# ğŸ“„ BondDocExtractor: Fine-Tune an LLM on 1M+ Financial Bond PDFs

This project enables scalable training of a language model to extract structured data from large-scale unstructured bond documents (PDFs). It uses a step-by-step QLoRA-based fine-tuning approach on real financial fixed-income bond documents.

---

## ğŸ“Š Objective

Train and deploy an LLM to extract structured JSON data (like issuer, ISIN, coupon rate, etc.) from unstructured financial bond PDFs â€” using a scalable, bootstrapped labeling and fine-tuning process.

---

## ğŸ“Œ Project Overview

```
Raw PDFs
   â”‚
   â”œâ”€â–¶ Text + Layout Extraction (pdfplumber)
   â”‚
   â”œâ”€â–¶ JSON Auto-Labeling using GPT/Gemini
   â”‚
   â”œâ”€â–¶ QLoRA Fine-Tuning (Axolotl)
   â”‚
   â””â”€â–¶ Deploy for Inference (Ollama / LangChain / API)
```

---

## âœ… PHASE 1: Data Preparation

### 1.1 Organize PDFs

Place your documents inside a directory:
```
/data/bonds_batch_1/*.pdf
```

### 1.2 Extract Text from PDFs (with Layout)

```python
import pdfplumber, json
from pathlib import Path

def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        return "\n".join([p.extract_text() or '' for p in pdf.pages])

pdf_dir = Path("/data/bonds_batch_1")
with open("raw_bonds_batch1.jsonl", "w") as f:
    for pdf_path in pdf_dir.glob("*.pdf"):
        text = extract_text_from_pdf(pdf_path)
        json.dump({"input": text}, f)
        f.write("\n")
```

---

## ğŸ¤– PHASE 2: Auto-Labeling with GPT / Gemini

### 2.1 Prompt-Based Labeling
Use OpenAI or Gemini APIs to generate structured JSON fields:
```python
prompt = f"""
### Task:
Extract bond details in JSON.

### Document:
{text[:3000]}

### Output:
{{
  "issuer": "...",
  "isin": "...",
  ...
}}
"""
```

Output file should be a `.jsonl`:
```json
{
  "instruction": "Extract bond details.",
  "input": "Issuer: ABC Corp\nISIN: ...",
  "output": {
    "issuer": "ABC Corp",
    "isin": "US1234567890"
  }
}
```

---

## ğŸ”§ PHASE 3: QLoRA Fine-Tuning with Axolotl

### 3.1 Install Axolotl

```bash
git clone https://github.com/OpenAccess-AI-Collective/axolotl
cd axolotl
pip install -e .
```

### 3.2 Create Config File

**`configs/qlora_bonds.yaml`**
```yaml
base_model: meta-llama/Meta-Llama-3-8B-Instruct
load_in_4bit: true
adapter: qlora
datasets:
  - path: ./train_bonds.jsonl
    type: alpaca
lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
num_epochs: 3
cutoff_len: 4096
val_set_size: 0.05
output_dir: ./output/qlora-bond-model
gradient_accumulation_steps: 4
per_device_train_batch_size: 2
bf16: true
```

### 3.3 Launch Training

```bash
accelerate launch axolotl/scripts/train.py configs/qlora_bonds.yaml
```

---

## ğŸš€ PHASE 4: Inference / Deployment

### 4.1 Use Fine-Tuned Model

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("output/qlora-bond-model", device_map="auto")
tokenizer = AutoTokenizer.from_pretrained("output/qlora-bond-model")

prompt = "### Instruction:\nExtract bond details\n\n### Document:\n<bond text>\n\n### Output:"
tokens = tokenizer(prompt, return_tensors="pt").to(model.device)
output = model.generate(**tokens, max_new_tokens=512)
print(tokenizer.decode(output[0], skip_special_tokens=True))
```

### 4.2 Serve Model via

- [ ] ğŸ§  Ollama (local inference)
- [ ] ğŸ§  vLLM / TGI for scalable APIs
- [ ] ğŸ§  LangChain + Streamlit for PDF UI

---

## ğŸ” PHASE 5: Iterative Bootstrapping

| Step | Sample Count |
|------|--------------|
| Manually label | 1,000 |
| Auto-label via GPT | 10,000 |
| Fine-tune | âœ… |
| Use model to label next batch | 100,000 |
| Retrain model | âœ… |
| Repeat for full 1M | â™»ï¸ |

---

## ğŸ“‚ Directory Structure

```
bond-extractor/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bonds_batch_1/*.pdf
â”œâ”€â”€ extracted/
â”‚   â””â”€â”€ raw_bonds_batch1.jsonl
â”œâ”€â”€ labeled/
â”‚   â””â”€â”€ train_bonds.jsonl
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ qlora_bonds.yaml
â”œâ”€â”€ output/
â”‚   â””â”€â”€ qlora-bond-model/
â””â”€â”€ README.md
```

---

## ğŸ§¹ TODOs

- [ ] PDF parallel extractor (Ray or multiprocessing)
- [ ] Auto-labeling script using OpenAI/Gemini API
- [ ] Fine-tuning wrapper
- [ ] Deployment using Ollama or vLLM

---

## ğŸ“¬ Contact

Built by Harish Kumar  
GitHub: [harish-nika](https://github.com/harish-nika)  
Email: harishkumar56278@gmail.com

---

## ğŸ‘ï¸ License

MIT License

